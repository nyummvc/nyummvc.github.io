<!DOCTYPE html>
<html lang="en">

<head>
    <title>MMVC</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">


    <link href="https://fonts.googleapis.com/css?family=B612+Mono|Cabin:400,700&display=swap" rel="stylesheet">

    <link rel="stylesheet" href="fonts/icomoon/style.css">
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css"
          integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">

    <link rel="stylesheet" href="css/jquery-ui.css">
    <link rel="stylesheet" href="css/owl.carousel.min.css">
    <link rel="stylesheet" href="css/owl.theme.default.min.css">
    <link rel="stylesheet" href="css/owl.theme.default.min.css">

    <link rel="stylesheet" href="css/jquery.fancybox.min.css">

    <link rel="stylesheet" href="fonts/flaticon/font/flaticon.css">

    <link rel="stylesheet" href="css/aos.css">
    <link href="css/jquery.mb.YTPlayer.min.css" media="all" rel="stylesheet" type="text/css">

    <link rel="stylesheet" href="css/style.css">
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->


</head>

<body data-spy="scroll" data-target=".site-navbar-target" data-offset="300">

<div class="site-wrap">

    <div class="site-mobile-menu site-navbar-target">
        <div class="site-mobile-menu-header">
            <div class="site-mobile-menu-close mt-3">
                <span class="icon-close2 js-menu-toggle"></span>
            </div>
        </div>
        <div class="site-mobile-menu-body"></div>
    </div>

    <div class="header-top">
        <div class="container" style="padding:20px">
            <div class="row align-items-center">
                <!-- <div class="col-12 col-lg-6 d-flex"> -->
                    <img src="./logo.jpg" width="15%">
                    <a class="ml-auto site-logo">
                       
                             &nbsp&nbsp<b style="color: rgb(71, 71, 71)">NYU M</b>ultimedia and <b style="color: rgb(71, 71, 71)">V</b>isual Computing Lab 
                    </a>
                    <a href="#"
                       class="ml-auto d-inline-block d-lg-none site-menu-toggle js-menu-toggle text-black"><span
                            class="icon-menu h3"></span></a>

                <!-- </div> -->
                <!-- <div class="col-12 col-lg-6 ml-auto d-flex">
                    <div class="ml-md-auto top-social d-none d-lg-inline-block">
                        <a href="#" class="d-inline-block p-3"> </a>
                        <a href="#" class="d-inline-block p-3"> </a>
                        <a href="#" class="d-inline-block p-3"> </a>
                    </div>

                </div> -->
                <!--          <div class="col-6 d-block d-lg-none text-right">-->

            </div>
        </div>
    </div>

    
    <div class="site-navbar py-2 js-sticky-header site-navbar-target d-none pl-0 d-lg-block" role="banner">

        <div class="container" style="padding-right=10%">
            <div class="d-flex align-items-right">
                <!-- <div class="mr-auto">
                    <a href="index.html">
                       <img src="./logo.png" width="10%"/>
                             &nbsp&nbsp<b>V</b>isual <b>I</b>nformatics Group @ University of <b>T</b>exas at <b>A</b>ustin
                    </a>
                </div> -->
                <div class="ml-auto">
                    <nav class="site-navigation position-relative text-right" role="navigation">
                        <ul class="site-menu main-menu js-clone-nav mr-auto d-none pl-0 d-lg-block">
                            <li class="active">
                                <a href="index.html" class="nav-link text-right">Home</a>
                            </li>
                            <li>
                                <a href="publication.html"" class="nav-link text-left">Publication</a>
                            </li>
                            <li>
                                <a href="group.html" class="nav-link text-left">Group</a>
                            </li>
                            <li>
                                <a href="resource.html" class="nav-link text-left">Resource</a>
                            </li>
                            <li>
                                <a href="prospective_students.html" class="nav-link text-left">Opening</a>
                            </li>
                            <!-- <li class="nav-item dropdown">
                                              <a class="nav-link dropdown-toggle" href="challenge.html" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                                   Challenge
                                 </a>
                                          <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                                           <a class="dropdown-item" href="challenge1.html">Tiny Object Detection Challenge</a>
                                           <a class="dropdown-item" href="challenge2.html">Image Restoration for UDC Challenge</a>
                                         </div>
                            </li>
                            <li>
                                <a href="callforpapers.html" class="nav-link text-left">Call for Papers</a>
                            </li>

                            <li>
                                <a href="speakers.html" class="nav-link text-left">Invited Speakers</a>
                            </li>

                            <li class="nav-item dropdown">
                                <a class="nav-link dropdown-toggle" href="challenge.html" id="navbarDropdown"
                                   role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                                    Previous
                                </a>
                                <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                                    <a class="dropdown-item" href="https://yuqian2.wixsite.com/forlq">RLQ'19</a>
                                </div>
                            </li> -->
                        </ul>
                    </nav>

                </div>

            </div>
        </div>

    </div>

</div>
        


<div class="site-section">
    <div class="container">
        <div class="row">
            <div class="col-lg-12">
                <p>Our group actively publishes in the fields of machine learning, computer vision, and interdisciplinary data science. Below are a list of recent and selected papers. A mark * denotes the author to be a MMVC student or Dr. Fang's mentee. An up-to-date full paper list can be found <a href="https://scholar.google.com/citations?hl=en&user=j-cyhzwAAAAJ&view_op=list_works&sortby=pubdate">here</a>.</p>
         
                                                                      
                <div class="section-title" style="margin-bottom: 30px">
                <h2>Publications</h2>
                </div>
                                                                      
                <b>2023</b>
					<hr />


                    <table cellpadding=5>
                        <tr>
                            <td><a href="main/big/PMPNET++.png"><img src="logos/cGPAligner.png" alt="Neural" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Lingjing Wang, Nan Zhou, Hao Huang, Jifei Wang, Xiang Li, <strong>Yi Fang</strong>. GP-Aligner: Unsupervised Groupwise Non-Rigid Point Set Registration Based On Optimizable Group Latent Descriptor. <i>IEEE Transactions on Geoscience and Remote Sensing <strong>(TGRS)</strong></i>, 2023, 60(1). DOI: 10.1109/TGRS.2022.3230413.
                                <img class="new" src="folder_name/image_name.image_extension" />
                                <br />
                                <a href="https://arxiv.org/pdf/2007.12979">[ArXiv]&nbsp&nbsp</a>
								<a href="https://arxiv.org/pdf/2007.12979.pdf">[PDF]&nbsp&nbsp</a>
                                <a href="https://ieeexplore.ieee.org/abstract/document/9994035">[IEEE Xplore]&nbsp&nbsp</a>

                            </td>
                        </tr>


                       <tr>
                            <td><a href="main/big/PMPNET++.png"><img src="logos/cGPAligner.png" alt="Neural" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Congcong Wen, Hao Huang, Yushen Liu, <strong>Yi Fang</strong>. Pyramid Learnable Tokens for 3D LiDAR Place Recognition. <i>2023 IEEE International Conference on Robotics and Automation <strong>(ICRA)</strong>, May 29 - June 2, 2023, ExCeL London, UK </i>
                                <img class="new" src="folder_name/image_name.image_extension" />
                                <br />

                                <a href="https://ieeexplore.ieee.org/abstract/document/9994035">[IEEE Xplore]&nbsp&nbsp</a>

                            </td>
                        </tr>

											                        <tr>
                            <td><a href="main/big/PMPNET++.png"><img src="logos/cGPAligner.png" alt="Neural" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Meng Wang, Yu-Shen Liu, Yue Gao, Kanle Shi, <strong>Yi Fang</strong>, Zhizhong Han. SHS-Net: Learning Signed Hyper Surfaces for Oriented Normal Estimation of Point Clouds. <i>2023 Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong>, Vancouver Convention Centre, Jun 18, 2023 – Thu, Jun 22, 2023</i>
                                <img class="new" src="folder_name/image_name.image_extension" />
                                <br />

                                <a href="https://ieeexplore.ieee.org/abstract/document/9994035">[IEEE Xplore]&nbsp&nbsp</a>

                            </td>
                        </tr>

											                        <tr>
             									                        <tr>
                            <td><a href="main/big/PMPNET++.png"><img src="logos/cGPAligner.png" alt="Neural" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Qing Li, Huifang Feng, Kanle Shi, Yue Gao, <strong>Yi Fang</strong>, Yu-Shen Liu, Zhizhong Han. LP-DIF: Learning Local Pattern-specific Deep Implicit Function for 3D Objects and Scenes. <i>2023 Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong>, Vancouver Convention Centre, Jun 18, 2023 – Thu, Jun 22, 2023</i>
                                <img class="new" src="folder_name/image_name.image_extension" />
                                <br />

                                <a href="https://ieeexplore.ieee.org/abstract/document/9994035">[IEEE Xplore]&nbsp&nbsp</a>

                            </td>
                        </tr>

                     
                

                    




                    </table>

                    <b>2022</b>
                    <hr />


                    <table cellpadding=5>

                        <tr>
                        <tr>
                            <td><a href="main/big/NEAF.jpg"><img src="logos/cManifoldLearning.png" alt="SPU" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Hao Huang, Cheng Chen, <strong>Yi Fang</strong>. Manifold Adversarial Learning for Cross-domain 3D Shape Representation <i>European Conference on Computer Vision. <strong>(ECCV)</strong></i>, 2022.
                                <img class="new" src="main/img/new.gif" />
                                <br />
                                <a href="https://link.springer.com/chapter/10.1007/978-3-031-19809-0_16">[Springer]&nbsp&nbsp</a>
                                
                            </td>
                        </tr>

                        <tr>
                            <td><a href="main/big/PMPNET++.png"><img src="logos/cNonRigid.png" alt="Neural" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Hao Huang, Cheng Chen, <strong>Yi Fang</strong>. Non-Rigid Multiple Point Set Registration Using Latent Gaussian Mixture. <i>2022 IEEE International Conference on Image Processing. <strong>(ICIP)</strong></i>, 2022, 45(1): 3181-3185.
                                <img class="new" src="main/img/new.gif" />
                                <br />
                               
                                <a href="https://ieeexplore.ieee.org/abstract/document/9897166">[IEEE Xplore]&nbsp&nbsp</a>
                          
                            </td>
                        </tr>

                        <tr>
                            <td><a href="main/big/NEAF.jpg"><img src="logos/cHSurf.png" alt="SPU" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Qing Li, Yu-Shen Liu, Jin-San Cheng, Cheng Wang, <strong>Yi Fang</strong>, Zhizhong Han. HSurf-Net: Normal Estimation for 3D Point Clouds by Learning Hyper Surfaces. <i>Thirty-Sixth Conference on Neural Information Processing Systems. <strong>(NeurIPS)</strong></i>, 2022.
                                <img class="new" src="main/img/new.gif" />
                                <br />
                                
                                <a href="https://arxiv.org/abs/2210.07158">[ArXiv]&nbsp&nbsp</a>
                               >
                            </td>
                        </tr>





                        <tr>
                            <td><a href="main/big/NEAF.jpg"><img src="logos/cLearningConsistencyAware.png" alt="SPU" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Junsheng Zhou, Baorui Ma, Yu-Shen Liu, <strong>Yi Fang</strong>, Zhizhong Han. Learning Consistency-Aware Unsigned Distance Functions Progressively from Raw Point Clouds. <i>Thirty-Sixth Conference on Neural Information Processing Systems. <strong>(NeurIPS)</strong></i>, 2022.
                                <img class="new" src="main/img/new.gif" />
                                <br />
                               
                                <a href="https://arxiv.org/abs/2210.02757">[ArXiv]&nbsp&nbsp</a>
                             
                            </td>
                        </tr>







                        <tr>
                            <td><a href="main/big/PMPNET++.png"><img src="logos/dSketchBased.png" alt="Neural" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Jie Qin, Shuaihang Yuan, Jiaxin Chen, Boulbaba Ben Amor, Nhat Hoang-Xuan, Chi-Bien Chu, Khoi-Nguyen Nguyen-Ngoc, Thien-Tri Cao, Nhat-Khang Ngo, Tuan-Luc Huynh, Hai-Dang Nguyen, Minh-Triet Tran, Haoyang Luo, Jianning Wang, Zheng Zhang, Zihao Xin, Yang Wang, Feng Wang, Ying Tang, Haiqin Chen, Yan Wang, Qunying Zhou, Ji Zhang, Hongyuan Wang, <strong>Yi Fang</strong>. SHREC’22 track: Sketch-based 3D shape retrieval in the wild. <i>Computers & Graphics</i> ,2022,107: 104-115.
                                <img class="new" src="main/img/new.gif" />
                                <br />
                                <a href="https://www.sciencedirect.com/science/article/pii/S0097849322001261">[IEEE Xplore]&nbsp&nbsp</a>
                            </td>
                        </tr>

                        <tr>
                            <td><a href="main/big/PMPNET++.png"><img src="logos/bProteinLigand.png" alt="Neural" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Luca Gagliardi, Andrea Raffo, Ulderico Fugacci, Silvia Biasotti, Walter Rocchia, Hao Huang, Boulbaba Ben Amor, Yuanyuan Zhang, Xiao Wang, Charles Christoffer, Daisuke Kihara, Apostolos Axenopoulos, Stelios Mylonas, Petros Daras, <strong>Yi Fang</strong>. SHREC 2022: Protein–ligand binding site recognition <i>Computers & Graphics</i>, 2022, 107: 20-31
                                <img class="new" src="main/img/new.gif" />
                                <br />
                                <a href="https://www.sciencedirect.com/science/article/pii/S0097849322001236">[ScienceDirect]&nbsp&nbsp</a>
                            </td>
                        </tr>

                        <tr>
                            <td><a href="main/big/PMPNET++.png"><img src="logos/bUIIQD.png" alt="Neural" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Yu Hao, Haoyang Pei, Yixuan Lyu, Zhongzheng Yuan, John-Ross Rizzo, Yao Wang,<strong>Yi Fang</strong>. Understanding the Impact of Image Quality and Distance of Objects to Object Detection Performance.
                                <img class="new" src="main/img/new.gif" />
                                <br />
                                <a href="https://arxiv.org/abs/2209.08237">[ArXiv]&nbsp&nbsp</a>
                            </td>
                        </tr>



                        <tr>
                            <td><a href="main/big/NEAF.jpg"><img src="logos/cOsama.png" alt="SPU" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Muhammad Osama Khan, <strong>Yi Fang</strong>. Implicit Neural Representations for Medical Imaging Segmentation <i>International Conference on Medical Image Computing and Computer-Assisted Intervention. <strong>(MICCAI)</strong></i>, 2022.
                                <img class="new" src="main/img/new.gif" />
                                <br />
                                <a href="https://link.springer.com/chapter/10.1007/978-3-031-16443-9_42">[Springer]&nbsp&nbsp</a>

                            </td>
                        </tr>


                        <tr>
                            <td><a href="main/big/NEAF.jpg"><img src="logos/c3DPC.png" alt="SPU" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Mengxi Wu, Hao Huang, <strong>Yi Fang</strong>. 3D point cloud completion with geometric-aware adversarial augmentation. <i>2022 26th International Conference on Pattern Recognition. <strong>(ICPR)</strong></i>, 2022.
                                <img class="new" src="main/img/new.gif" />
                                <br />
                                
                                <a href="https://ieeexplore.ieee.org/abstract/document/9956045">[IEEE]&nbsp&nbsp</a>
                            </td>
                        </tr>



                        <tr>
                            <td><a href="main/big/PMPNET++.png"><img src="logos/bDoA.png" alt="Neural" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Yu Hao, Junchi Feng, John-Ross Rizzo, Yao Wang, <strong>Yi Fang</strong>. Detect and Approach: Close-Range Navigation Support for People with Blindness and Low Vision. 
                                <img class="new" src="main/img/new.gif" />
                                <br />

                                <a href="https://arxiv.org/abs/2208.08477">[ArXiv]</a>
                            </td>
                        </tr>


                        <tr>
                            <td><a href="main/big/PMPNET++.png"><img src="logos/cMultiOrgan.png" alt="Neural" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Haoyu Fang, Xiaofeng Yang, <strong>Yi Fang</strong>. Multi-organ Segmentation Network with Adversarial Performance Validator.
                                <img class="new" src="main/img/new.gif" />
                                <br />

                                <a href="https://arxiv.org/abs/2204.07850">[ArXiv]</a>
                            </td>
                        </tr>


                        <tr>
                            <td><a href="main/big/PMPNET++.png"><img src="logos/c3DOAE.png" alt="Neural" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Junsheng Zhou, Xin Wen, Yu-Shen Liu, Zhizhong Han <strong>Yi Fang</strong>. 3D-OAE: Occlusion Auto-Encoders for Self-Supervised Learning on Point Clouds.
                                <img class="new" src="main/img/new.gif" />
                                <br />

                                <a href="https://arxiv.org/abs/2203.14084">[ArXiv]</a>
                            </td>
                        </tr>


                        <tr>
                            <td><a href="main/big/NEAF.jpg"><img src="logos/cNetworkAware.png" alt="SPU" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Zhongzheng Yuan, Tommy Azzino, Yu Hao, Yixuan Lyu, Haoyang Pei, Alain Boldini, Marco Mezzavilla, Mahya Beheshti, Maurizio Porfiri, Todd E Hudson, William Seiple, <strong>Yi Fang</strong>, Sundeep Rangan, Yao Wang, John-Ross Rizzo. Network-Aware 5G Edge Computing for Object Detection: Augmenting Wearables to “See” More, Farther and Faster. <i> <strong>IEEE Access</strong></i>, 2022.
                                <img class="new" src="main/img/new.gif" />
                                <br />
                                <a href="https://ieeexplore.ieee.org/abstract/document/9730919">[IEEE]&nbsp&nbsp</a>
                              
                            </td>
                        </tr>

                        <tr>
                            <td><a href="main/big/NEAF.jpg"><img src="logos/cUnCatSpe.png" alt="SPU" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Xiang Li, Lingjing Wang, <strong>Yi Fang</strong>. Unsupervised Category-Specific Partial Point Set Registration via Joint Shape Completion and Registration <i>IEEE Transactions on Visualization and Computer Graphics. <strong>(TVCG)</strong></i>, 2022.
                                <img class="new" src="main/img/new.gif" />
                                <br />
                                <a href="https://ieeexplore.ieee.org/abstract/document/9729524">[IEEE]&nbsp&nbsp</a>
                                
                            </td>
                        </tr>

                        <tr>
                            <td><a href="main/big/NEAF.jpg"><img src="logos/cMetaDet3D.png" alt="SPU" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Shuaihang Yuan, Xiang Li, Hao Huang, <strong>Yi Fang</strong>. Meta-Det3D: Learn to Learn Few-Shot 3D Object Detection <i>Proceedings of the Asian Conference on Computer Vision. <strong>(ACCV)</strong></i>, 2022.
                                <img class="new" src="main/img/new.gif" />
                                <br />
                                <a href="https://openaccess.thecvf.com/content/ACCV2022/html/Yuan_Meta-Det3D_Learn_to_Learn_Few-Shot_3D_Object_Detection_ACCV_2022_paper.html">[OpenAccess]&nbsp&nbsp</a>
                               
                            </td>
                        </tr>






                    </table>


                    <b>2021</b>
                    <hr />


                    <table cellpadding=5>
                        <tr>
                            <td><a href="main/big/PMPNET++.png"><img src="logos/bMetaLearning3D.png" alt="Neural" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Hao Huang, Xiang Li, Lingjing Wang, <strong>Yi Fang</strong>. 3D-MetaConNet: Meta-learning for 3D Shape Classification and Segmentation. <i>2021 IEEE International Conference on 3D Vision. <strong>(3DV)</strong></i>, 2021.
                                <img class="new" src="main/img/new.gif" />
                                <br />
                                <a href="https://ieeexplore.ieee.org/abstract/document/9665930">[IEEE]&nbsp&nbsp</a>
                              
                            </td>
                        </tr>

                        <tr>
                            <td><a href="main/big/PMPNET++.png"><img src="logos/d3DMetaSeg.png" alt="Neural" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Yu Hao, <strong>Yi Fang</strong>. 3D Meta-Segmentation Neural Network.
                                <img class="new" src="main/img/new.gif" />
                                <br />

                                <a href="https://arxiv.org/abs/2110.04297">[ArXiv]</a>
                            </td>
                        </tr>

                        <tr>
                            <td><a href="main/big/PMPNET++.png"><img src="logos/bMetaLearning3D.png" alt="Neural" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Yu Hao, <strong>Yi Fang</strong>. Meta-Learning 3D Shape Segmentation Functions.
                                <img class="new" src="main/img/new.gif" />
                                <br />

                                <a href="https://arxiv.org/abs/2110.03854">[ArXiv]</a>
                            </td>
                        </tr>


                        <tr>
                            <td><a href="main/big/PMPNET++.png"><img src="logos/bRAR.png" alt="Neural" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Yu Hao, <strong>Yi Fang</strong>. RAR: Region-Aware Point Cloud Registration.
                                <img class="new" src="main/img/new.gif" />
                                <br />

                                <a href="https://arxiv.org/abs/2110.03544">[ArXiv]</a>
                            </td>
                        </tr>




                        <tr>
                            <td><a href="main/big/NEAF.jpg"><img src="logos/dInconspicuous.png" alt="SPU" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Alain Boldini, Andy Louis Garcia, Marc Sorrentino, Mahya Beheshti, Okpe Ogedegbe, <strong>Yi Fang</strong>, Maurizio Porfiri, John-Ross Rizzo. An inconspicuous, integrated electronic travel aid for visual impairment. <i>ASME Letters in Dynamic Systems and Control </i>, 2021.
                                <img class="new" src="main/img/new.gif" />
                                <br />
                                <a href="https://asmedigitalcollection.asme.org/lettersdynsys/article/1/4/041004/1098823/An-Inconspicuous-Integrated-Electronic-Travel-Aid">[ASME]&nbsp&nbsp</a>
                                
                            </td>
                        </tr>

                        <tr>
                            <td><a href="main/big/KT-NET_AAAI2023.jpg"><img src="logos/eAdaptive.png" alt="SPU" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Hao Huang, <strong>Yi Fang</strong>. Adaptive Wavelet Transformer Network for 3D Shape Representation Learning. <i>International Conference on Learning Representations <strong>(ICLR)</strong></i>, 2021.
                                <img class="new" src="main/img/new.gif" />
                                <br />

                                <a href="https://openreview.net/forum?id=5MLb3cLCJY&trk=public_post_comment-text">[OpenReview]</a>

                            </td>
                        </tr>

                        <tr>
                            <td><a href="main/big/PMPNET++.png"><img src="logos/dContinuityLearner.png" alt="Neural" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Haoyu Fang, Jing Zhu, <strong>Yi Fang</strong>. ContinuityLearner: Geometric continuity feature learning for lane segmentation.
                                <img class="new" src="main/img/new.gif" />
                                <br />

                                <a href="https://arxiv.org/abs/2108.03507">[ArXiv]</a>
                            </td>
                        </tr>

                        <tr>
                            <td><a href="main/big/KT-NET_AAAI2023.jpg"><img src="logos/eGeometryAware.png" alt="SPU" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Xiang Li, Congcong Wen, Lingjing Wang, <strong>Yi Fang</strong>. Geometry-aware segmentation of remote sensing images via joint height estimation. <i>IEEE Geoscience and Remote Sensing Letters <strong>(GRSL)</strong></i>, 2021.
                                <img class="new" src="main/img/new.gif" />
                                <br />

                                <a href="https://ieeexplore.ieee.org/abstract/document/9361998">[IEEE]</a>

                            </td>
                        </tr>


                        <tr>
                            <td><a href="main/big/KT-NET_AAAI2023.jpg"><img src="logos/aGVAE.png" alt="SPU" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Hao Huang, Boulbaba Ben Amor, Xichan Lin, Fan Zhu, <strong>Yi Fang</strong>. G-VAE, a Geometric Convolutional VAE for ProteinStructure Generation.
                                <img class="new" src="main/img/new.gif" />
                                <br />


                                <a href="https://arxiv.org/abs/2106.11920">[ArXiv]</a>

                            </td>
                        </tr>


                        <tr>
                            <td><a href="main/big/KT-NET_AAAI2023.jpg"><img src="logos/aResNet.png" alt="SPU" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Hao Huang, Boulbaba Ben Amor, Xichan Lin, Fan Zhu,  <strong>Yi Fang</strong>. Residual Networks as Flows of Velocity Fields for Diffeomorphic Time Series Alignment.
                                <img class="new" src="main/img/new.gif" />
                                <br />


                                <a href="https://arxiv.org/abs/2106.11911">[ArXiv]</a>

                            </td>
                        </tr>


             


                        <tr>
                            <td><a href="main/big/KT-NET_AAAI2023.jpg"><img src="logos/aWavelet.png" alt="SPU" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Hao Huang, <strong>Yi Fang</strong>. Adaptive wavelet transformer network for 3d shape representation learning.
                                <img class="new" src="main/img/new.gif" />
                                <br />


                                <a href="https://openreview.net/forum?id=5MLb3cLCJY&trk=public_post_comment-text">[OpenReview]</a>

                            </td>
                        </tr>


                        <tr>
                            <td><a href="main/big/KT-NET_AAAI2023.jpg"><img src="logos/aAudi.png" alt="SPU" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Daohan Lu, <strong>Yi Fang</strong>. Audi-Exchange: AI-Guided Hand-Based Actions To Assist Human-Human Interactions for the Blind and the Visually Impaired. <i>Proceedings of the IEEE/CVF International Conference on Computer Vision. <strong>(ICCV)</strong></i>
                                <img class="new" src="main/img/new.gif" />
                                <br />


                                <a href="https://openaccess.thecvf.com/content/ICCV2021W/ACVR/html/Lu_Audi-Exchange_AI-Guided_Hand-Based_Actions_To_Assist_Human-Human_Interactions_for_the_ICCVW_2021_paper.html">[OpenAccess]</a>

                            </td>
                        </tr>


                        <tr>
                            <td><a href="main/big/KT-NET_AAAI2023.jpg"><img src="logos/dCov19VisDis.png" alt="SPU" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>John-Ross Rizzo, Mahya Beheshti, Steven Flanagan, Nicholas A Giudice <strong>Yi Fang</strong>. COVID-19 and visual disability: Can’t look and now don’t touch. <i>American Academy of Physical Medicine and Rehabilitation. <strong>(AAPM&R)</strong></i>, 2021(13)
                                <img class="new" src="main/img/new.gif" />
                                <br />


                                <a href="https://digitalcommons.library.umaine.edu/cgi/viewcontent.cgi?article=1078&context=c19_teach_doc">[DigitalCommons@UMaine]</a>

                            </td>
                        </tr>




                    </table>


                    <b>2020</b>
                    <hr />



                    <table cellpadding=5>


                        <tr>
                            <td><a href="main/big/KT-NET_AAAI2023.jpg"><img src="logos/d3DMotionNet.png" alt="SPU" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Shuaihang Yuan, Xiang Li, Anthony Tzes, <strong>Yi Fang</strong>. 3dmotion-net: Learning continuous flow function for 3d motion prediction. <i>2020 IEEE/RSJ International Conference on Intelligent Robots and Systems. <strong>(IROS)</strong></i>, 2020:8154-8160
                                <img class="new" src="main/img/new.gif" />
                                <br />
                                <a href="https://ieeexplore.ieee.org/abstract/document/9341671">[IEEE Xplore]</a>
                            </td>
                        </tr>


                        <tr>
                            <td><a href="main/big/KT-NET_AAAI2023.jpg"><img src="logos/d3DMetaRegister.png" alt="SPU" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Lingjing Wang, Yu Hao, Xiang Li,  <strong>Yi Fang</strong>. 3D Meta-Registration: Learning to Learn Registration of 3D Point Clouds.
                                <img class="new" src="main/img/new.gif" />
                                <br />
                                <a href="https://arxiv.org/abs/2010.11504">[arXiv]</a>
                            </td>
                        </tr>


                        <tr>
                            <td><a href="main/big/KT-NET_AAAI2023.jpg"><img src="logos/d3DMetaPointSignature.png" alt="SPU" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Hao Huang, Lingjing Wang, Xiang Li,  <strong>Yi Fang</strong>. 3D Meta Point Signature: Learning to Learn 3D Point Signature for 3D Dense Shape Correspondence.

                                <img class="new" src="main/img/new.gif" />
                                <br />
                                <a href="https://arxiv.org/abs/2010.11159">[arXiv]</a>
                            </td>
                        </tr>


                        <tr>
                            <td><a href="main/big/KT-NET_AAAI2023.jpg"><img src="logos/dDeep3DAligner.png" alt="SPU" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Lingjing Wang, Xiang Li,  <strong>Yi Fang</strong>. Deep-3DAligner: Unsupervised 3D Point Set Registration Network With Optimizable Latent Vector.

                                <img class="new" src="main/img/new.gif" />
                                <br />
                                <a href="https://arxiv.org/abs/2010.00321">[arXiv]</a>
                            </td>
                        </tr>



                        <tr>
                            <td><a href="main/big/KT-NET_AAAI2023.jpg"><img src="logos/dSupervisedPartialPoint.png" alt="SPU" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Lingjing Wang, Xiang Li,  <strong>Yi Fang</strong>. Unsupervised Partial Point Set Registration via Joint Shape Completion and Registration.

                                <img class="new" src="main/img/new.gif" />
                                <br />
                                <a href="https://arxiv.org/abs/2009.05290">[arXiv]</a>
                            </td>
                        </tr>




                        <tr>
                            <td><a href="main/big/KT-NET_AAAI2023.jpg"><img src="logos/dHeightEstimator.png" alt="SPU" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Xiang Li, Mingyang Wang, <strong>Yi Fang</strong>. Height estimation from single aerial images using a deep ordinal regression network. <i>IEEE Geoscience and Remote Sensing Letters. <strong>(IEEE)</strong></i>, 2020(19): 1-5


                                <img class="new" src="main/img/new.gif" />
                                <br />
                                <a href="https://ieeexplore.ieee.org/abstract/document/9190011">[IEEE]</a>
                            </td>
                        </tr>


             

                        <tr>
                            <td><a href="main/big/KT-NET_AAAI2023.jpg"><img src="logos/aRIMDF.png" alt="SPU" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Hao Huang, Jianchun Chen, Xiang Li, Lingjing Wang, <strong>Yi Fang</strong>. Robust image matching by dynamic feature selection


                                <img class="new" src="main/img/new.gif" />
                                <br />
                                <a href="https://arxiv.org/abs/2008.05708">[arXiv]</a>
                            </td>
                        </tr>


                        <tr>
                            <td><a href="main/big/KT-NET_AAAI2023.jpg"><img src="logos/dDanceNet.png" alt="SPU" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Xiang Li, Lingjing Wang, Mingyang Wang, Congcong Wen <strong>Yi Fang</strong>. DANCE-NET: Density-aware convolution networks with context encoding for airborne LiDAR point cloud classification. <i>ISPRS Journal of Photogrammetry and Remote Sensing. <strong>(ISPRS)</strong></i>, 2020(166): 128-139


                                <img class="new" src="main/img/new.gif" />
                                <br />
                                <a href="https://www.sciencedirect.com/science/article/abs/pii/S0924271620301490">[ScienceDirect]</a>
                            </td>
                        </tr>

                        <tr>
                            <td><a href="main/big/KT-NET_AAAI2023.jpg"><img src="logos/aGPAUN.png" alt="SPU" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Lingjing Wang, Xiang Li, <strong>Yi Fang</strong>. GP-Aligner: Unsupervised Non-rigid Groupwise Point Set Registration Based On Optimized Group Latent Descriptor.


                                <img class="new" src="main/img/new.gif" />
                                <br />
                                <a href="https://arxiv.org/abs/2007.12979">[arXiv]</a>
                            </td>
                        </tr>

                        <tr>
                            <td><a href="main/big/KT-NET_AAAI2023.jpg"><img src="logos/aDTN3D.png" alt="SPU" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Shuaihang Yuan, Xiang Li, <strong>Yi Fang</strong>. DeepTracking-Net: 3D Tracking with Unsupervised Learning of Continuous Flow.


                                <img class="new" src="main/img/new.gif" />
                                <br />
                                <a href="https://arxiv.org/abs/2006.13848">[arXiv]</a>
                            </td>
                        </tr>

                        <tr>
                            <td><a href="main/big/KT-NET_AAAI2023.jpg"><img src="logos/ULGRTS.png" alt="SPU" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Lingjing Wang, Yi Shi, Xiang Li, <strong>Yi Fang</strong>. Unsupervised learning of global registration of temporal sequence of point clouds.


                                <img class="new" src="main/img/new.gif" />
                                <br />
                                <a href="https://arxiv.org/abs/2006.12378">[arXiv]</a>
                            </td>
                        </tr>

                        <tr>
                            <td><a href="main/big/KT-NET_AAAI2023.jpg"><img src="logos/FoDRS.png" alt="SPU" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Jingyu Deng, Xiang Li, <strong>Yi Fang</strong>. Few-shot object detection on remote sensing images.


                                <img class="new" src="main/img/new.gif" />
                                <br />
                                <a href="https://arxiv.org/abs/2006.07826">[arXiv]</a>
                            </td>
                        </tr>

                        <tr>
                            <td><a href="main/big/KT-NET_AAAI2023.jpg"><img src="logos/UL3DPS.png" alt="SPU" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Lingjing Wang, Xiang Li,  <strong>Yi Fang</strong>. Unsupervised learning of 3D point set registration.


                                <img class="new" src="main/img/new.gif" />
                                <br />
                                <a href="https://arxiv.org/abs/2006.06200">[arXiv]</a>
                            </td>
                        </tr>

                        <tr>
                            <td><a href="main/big/KT-NET_AAAI2023.jpg"><img src="logos/GasOR.png" alt="SPU" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Lingjing Wang, Xiang Li,  <strong>Yi Fang</strong>. Geometry-Aware Segmentation of Remote Sensing Images via Implicit Height Estimation.


                                <img class="new" src="main/img/new.gif" />
                                <br />
                                <a href="https://arxiv.org/abs/2006.05848">[arXiv]</a>
                            </td>
                        </tr>

                        <tr>
                            <td><a href="main/big/KT-NET_AAAI2023.jpg"><img src="logos/eTopConstrained.png" alt="SPU" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Lingjing Wang, Congcong Wen, Xiang Li,  <strong>Yi Fang</strong>. Topology constrained shape correspondence. <i>IEEE transactions on visualization and computer graphics. <strong>(IEEE)</strong></i>, 2020(27): 3926-3937



                                <img class="new" src="main/img/new.gif" />
                                <br />
                                <a href="https://ieeexplore.ieee.org/abstract/document/9091324">[IEEE]</a>
                            </td>
                        </tr>


                        <tr>
                            <td><a href="main/big/KT-NET_AAAI2023.jpg"><img src="logos/ACA.png" alt="SPU" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Samridha Shrestha, Daohan Lu, Hanlin Tian, Qiming Cao, Julie Liu, John-Ross Rizzo, William H Seiple, Maurizio Porfiri, Xiang Li,  <strong>Yi Fang</strong>. Active crowd analysis for pandemic risk mitigation for blind or visually impaired persons. <i>European Conference on Computer Vision. <strong>(ECCV)</strong></i>, 2020: 422-439



                                <img class="new" src="main/img/new.gif" />
                                <br />
                                <a href="https://link.springer.com/chapter/10.1007/978-3-030-66823-5_25#citeas">[Springer]</a>
                            </td>
                        </tr>

                        <tr>
                            <td><a href="main/big/KT-NET_AAAI2023.jpg"><img src="logos/eMDANet.png" alt="SPU" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Jing Zhu, Yunxiao Shi, Mengwei Ren,  <strong>Yi Fang</strong>. MDA-net: memorable domain adaptation network for monocular depth estimation. <i>British Machine Vision Conference 2020</i>



                                <img class="new" src="main/img/new.gif" />
                                <br />
                                <a href="https://www.bmvc2020-conference.com/assets/papers/0790.pdf">[BMVC]</a>
                            </td>
                        </tr>


                        <tr>
                            <td><a href="main/big/KT-NET_AAAI2023.jpg"><img src="logos/UnsupervisedShapeDescriptor.png" alt="SPU" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Yi Shi, Mengchen Xu, Shuaihang Yuan,  <strong>Yi Fang</strong>. Unsupervised deep shape descriptor with point distribution learning. <i>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</i>, 2020: 9353-9362



                                <img class="new" src="main/img/new.gif" />
                                <br />
                                <a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Shi_Unsupervised_Deep_Shape_Descriptor_With_Point_Distribution_Learning_CVPR_2020_paper.html">[OpenAccess]</a>
                            </td>
                        </tr>

                        <tr>
                            <td><a href="main/big/KT-NET_AAAI2023.jpg"><img src="logos/FewShotLearning.png" alt="SPU" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Lingjing Wang, Xiang Li,  <strong>Yi Fang</strong>. Few-shot learning of part-specific probability space for 3D shape segmentation. <i>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</i>, 2020: 4504-4513



                                <img class="new" src="main/img/new.gif" />
                                <br />
                                <a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Wang_Few-Shot_Learning_of_Part-Specific_Probability_Space_for_3D_Shape_Segmentation_CVPR_2020_paper.html">[OpenAccess]</a>
                            </td>
                        </tr>


                        <tr>
                            <td><a href="main/big/KT-NET_AAAI2023.jpg"><img src="logos/ReferenceGridAssistedNetwork.png" alt="SPU" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Jing Zhu,  <strong>Yi Fang</strong>. Reference grid-assisted network for 3D point signature learning from point clouds. <i>Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</i>, 2020: 211-220



                                <img class="new" src="main/img/new.gif" />
                                <br />
                                <a href="http://openaccess.thecvf.com/content_WACV_2020/html/Zhu_Reference_Grid-assisted_Network_for_3D_Point_Signature_Learning_from_Point_WACV_2020_paper.html">[OpenAccess]</a>
                            </td>
                        </tr>


                        <tr>
                            <td><a href="main/big/KT-NET_AAAI2023.jpg"><img src="logos/ROSS.png" alt="SPU" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Shuaihang Yuan, <strong>Yi Fang</strong>. ROSS: Robust learning of one-shot 3D shape segmentation. <i>Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</i>, 2020: 1961-1969



                                <img class="new" src="main/img/new.gif" />
                                <br />
                                <a href="https://openaccess.thecvf.com/content_WACV_2020/html/Yuan_ROSS_Robust_Learning_of_One-shot_3D_Shape_Segmentation_WACV_2020_paper.html">[OpenAccess]</a>
                            </td>
                        </tr>


                        <tr>
                            <td><a href="main/big/KT-NET_AAAI2023.jpg"><img src="logos/CrossSafe.png" alt="SPU" width="200" /></a></td>
                            <td>
                                <span class="sequence"></span>Shuaihang Yuan, <strong>Yi Fang</strong>. Cross-Safe: A computer vision-based approach to make all intersection-related pedestrian signals accessible for the visually impaired. <i>Advances in Computer Vision: Proceedings of the 2019 Computer Vision Conference <strong>(CVC)</strong></i>, 2020:132-146



                                <img class="new" src="main/img/new.gif" />
                                <br />
                                <a href="https://link.springer.com/chapter/10.1007/978-3-030-17798-0_13">[Springer]</a>
                            </td>
                        </tr>





                    </table>

            </div>

        </div>
        
<!-- END section -->


<div class="footer">
    <div class="container">
        <div class="row">
            <div class="col-12">
                <div class="copyright">
                    <p>
                        <!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
                        Copyright &copy;<script>document.write(new Date().getFullYear());</script>
                        All rights reserved | Built upon <a
                            href="https://colorlib.com" target="_blank">Colorlib</a>
                        <!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
                        </p>
                        
                </div>
            </div>
        </div>
    </div>
</div>

</div>
<!-- .site-wrap -->


<!-- loader -->
<!-- <div id="loader" class="show fullscreen">
    <svg class="circular" width="48px" height="48px">
        <circle class="path-bg" cx="24" cy="24" r="22" fill="none" stroke-width="4" stroke="#eeeeee"/>
        <circle class="path" cx="24" cy="24" r="22" fill="none" stroke-width="4" stroke-miterlimit="10"
                stroke="#ff5e15"/>
    </svg>
</div> -->

<script src="js/jquery-3.3.1.min.js"></script>
<script src="js/jquery-migrate-3.0.1.min.js"></script>
<script src="js/jquery-ui.js"></script>
<script src="js/popper.min.js"></script>
<script src="js/bootstrap.min.js"></script>
<script src="js/owl.carousel.min.js"></script>
<script src="js/jquery.stellar.min.js"></script>
<script src="js/jquery.countdown.min.js"></script>
<script src="js/bootstrap-datepicker.min.js"></script>
<script src="js/jquery.easing.1.3.js"></script>
<script src="js/aos.js"></script>
<script src="js/jquery.fancybox.min.js"></script>
<script src="js/jquery.sticky.js"></script>
<script src="js/jquery.mb.YTPlayer.min.js"></script>

<script src="js/main.js"></script>

</body>

</html>
