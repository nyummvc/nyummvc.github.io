<!DOCTYPE html>
<html lang="en">

<head>
    <title>MMVC</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">


    <link href="https://fonts.googleapis.com/css?family=B612+Mono|Cabin:400,700&display=swap" rel="stylesheet">

    <link rel="stylesheet" href="fonts/icomoon/style.css">
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css"
          integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">

    <link rel="stylesheet" href="css/jquery-ui.css">
    <link rel="stylesheet" href="css/owl.carousel.min.css">
    <link rel="stylesheet" href="css/owl.theme.default.min.css">
    <link rel="stylesheet" href="css/owl.theme.default.min.css">

    <link rel="stylesheet" href="css/jquery.fancybox.min.css">

    <link rel="stylesheet" href="fonts/flaticon/font/flaticon.css">

    <link rel="stylesheet" href="css/aos.css">
    <link href="css/jquery.mb.YTPlayer.min.css" media="all" rel="stylesheet" type="text/css">

    <link rel="stylesheet" href="css/style.css">
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->


</head>

<body data-spy="scroll" data-target=".site-navbar-target" data-offset="300">

<div class="site-wrap">

    <div class="site-mobile-menu site-navbar-target">
        <div class="site-mobile-menu-header">
            <div class="site-mobile-menu-close mt-3">
                <span class="icon-close2 js-menu-toggle"></span>
            </div>
        </div>
        <div class="site-mobile-menu-body"></div>
    </div>

    <div class="header-top">
        <div class="container" style="padding:20px">
            <div class="row align-items-center">
                <!-- <div class="col-12 col-lg-6 d-flex"> -->
                    <img src="./logo.jpg" width="15%">
                    <a class="ml-auto site-logo">
                       
                             &nbsp&nbsp<b style="color: rgb(71, 71, 71)">NYU M</b>ultimedia and <b style="color: rgb(71, 71, 71)">V</b>isual Computing Lab 
                    </a>
                    <a href="#"
                       class="ml-auto d-inline-block d-lg-none site-menu-toggle js-menu-toggle text-black"><span
                            class="icon-menu h3"></span></a>

                <!-- </div> -->
                <!-- <div class="col-12 col-lg-6 ml-auto d-flex">
                    <div class="ml-md-auto top-social d-none d-lg-inline-block">
                        <a href="#" class="d-inline-block p-3"> </a>
                        <a href="#" class="d-inline-block p-3"> </a>
                        <a href="#" class="d-inline-block p-3"> </a>
                    </div>

                </div> -->
                <!--          <div class="col-6 d-block d-lg-none text-right">-->

            </div>
        </div>
    </div>

    
    <div class="site-navbar py-2 js-sticky-header site-navbar-target d-none pl-0 d-lg-block" role="banner">

        <div class="container" style="padding-right=10%">
            <div class="d-flex align-items-right">
                <!-- <div class="mr-auto">
                    <a href="index.html">
                       <img src="./logo.png" width="10%"/>
                             &nbsp&nbsp<b>V</b>isual <b>I</b>nformatics Group @ University of <b>T</b>exas at <b>A</b>ustin
                    </a>
                </div> -->
                <div class="ml-auto">
                    <nav class="site-navigation position-relative text-right" role="navigation">
                        <ul class="site-menu main-menu js-clone-nav mr-auto d-none pl-0 d-lg-block">
                            <li class="active">
                                <a href="index.html" class="nav-link text-right">Home</a>
                            </li>
                            <li>
                                <a href="publication.html"" class="nav-link text-left">Publication</a>
                            </li>
                            <li>
                                <a href="group.html" class="nav-link text-left">Group</a>
                            </li>
                            <li>
                                <a href="resource.html" class="nav-link text-left">Resource</a>
                            </li>
                            <li>
                                <a href="prospective_students.html" class="nav-link text-left">Opening</a>
                            </li>
                            <!-- <li class="nav-item dropdown">
                                              <a class="nav-link dropdown-toggle" href="challenge.html" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                                   Challenge
                                 </a>
                                          <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                                           <a class="dropdown-item" href="challenge1.html">Tiny Object Detection Challenge</a>
                                           <a class="dropdown-item" href="challenge2.html">Image Restoration for UDC Challenge</a>
                                         </div>
                            </li>
                            <li>
                                <a href="callforpapers.html" class="nav-link text-left">Call for Papers</a>
                            </li>

                            <li>
                                <a href="speakers.html" class="nav-link text-left">Invited Speakers</a>
                            </li>

                            <li class="nav-item dropdown">
                                <a class="nav-link dropdown-toggle" href="challenge.html" id="navbarDropdown"
                                   role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                                    Previous
                                </a>
                                <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                                    <a class="dropdown-item" href="https://yuqian2.wixsite.com/forlq">RLQ'19</a>
                                </div>
                            </li> -->
                        </ul>
                    </nav>

                </div>

            </div>
        </div>

    </div>

</div>


<div class="site-blocks-cover " style="background-image: url('./background.jpg');"
     data-stellar-background-ratio="1">
    <div class="container">
        <div class="row align-items-center justify-content-center">
            <div class="col-md-10 text-center" data-aos="fade-up">

            </div>
        </div>
    </div>
</div>

<div class="site-section">
    <div class="container">
        <div class="row">
            <div class="col-lg-12">
                <div class="section-title" style="margin-bottom:20px">
                    <h2>News</h2>
                </div>
                <div class="trend-entry d-flex">
                    <div class="trend-contents">

                        <b style="color:rgb(68, 68, 68)"><i>If you are here to seek "TL;DR"...</i></b>
                         <ul style="margin-bottom:5px">
                        <li><b style="color:rgb(71, 71, 71)">Question</b>: what should I read, if I just want to have a very quick glance at what VITA is currently digging on? </li> 
                        <li><b style="color:rgb(71, 71, 71)">Answer</b>: we pick five papers that somewhat represent our recent flavors, as "chef's choice". The list will change over time, of course : <a href="https://jmlr.org/papers/volume23/21-0308/21-0308.pdf">[Learning to Optimize, JMLR 2022]</a> , <a href="https://arxiv.org/pdf/2204.00928.pdf">[SinNeRF, ECCV 2022]</a> , <a href="https://proceedings.neurips.cc/paper/2021/file/7c220a2091c26a7f5e9f1cfb099511e3-Paper.pdf">[TransGAN, NeurIPS 2021]</a> , <a href="https://openreview.net/forum?id=Cnon5ezMHtu">[Theory-Guided NAS, ICLR 2021]</a> , <a href="https://proceedings.neurips.cc/paper/2020/file/b6af2c9703f203a2794be03d443af2e3-Paper.pdf">[BERT Lottery Ticket, NeurIPS 2020]</a> 
                        </li> 
                                            <p>
                    </ul>

                    <b style="color:rgb(68, 68, 68)">[Dec. 2022]</b>
                        <ul style="margin-bottom:5px">
                            <li> We are grateful to receive the Best Paper Award from LoG 2022 <a href="https://openreview.net/forum?id=dF6aEW3_62O">[Paper]</a></li> 
                            <li> Dr. Wang is grateful to receive the IEEE biennial "AI's 10 To Watch" award in 2022</li>
                             <li> VITA Ph.D. student <a href="https://yifanjiang19.github.io/">Yifan Jiang</a> is selected to receive a 2022 academic year Apple Scholars in AI/ML PhD fellowship </a> </li>
                        </ul>

                    <b style="color:rgb(68, 68, 68)">[Nov. 2022]</b>
                        <ul style="margin-bottom:5px">
                            <li> VITA Ph.D. student <a href="https://ir1d.github.io/">Dejia Xu</a> is selected to receive a 2022 academic year Snap Research Fellowship </a> </li>
                            <li> Our group is selected to be supported by the Meta Reality Labs Research Gift Award </li>
                            <li> Our group is selected to be supported by the Google TensorFlow Model Garden Award (again) </li>
                            <li>3 AAAI'23 (safeguarded L2O + federated robustness + efficient ViT) accepted </li> 
                            <li>1 LoG'22 (untrained graph LTH) accepted </li> 
                        </ul>

                    <b style="color:rgb(68, 68, 68)">[Oct. 2022]</b>
                        <ul style="margin-bottom:5px">
                            <li>1 WSDM'23 (search behavior prediction) accepted </li> 
                            <li>1 WACV'23 (imbalance in medical image localization) accepted </li> 
                        </ul>

                     <b style="color:rgb(68, 68, 68)">[Sep. 2022]</b>
                        <ul style="margin-bottom:5px">
                            <li>11 NeurIPS'22 (DAG convergence + INR DSP theory + M<sup>3</sup>ViT + back razor + randomized channel shuffling + symbolic TCC + GCN gradient + trapping backdoor + multimodal training + sparse few-shot learning + hypergraph contrastive learning) accepted </li> 
                            <li>1 NeurIPS Benchmark Track'22 (large-scale graph training) accepted </li> 
                        </ul>

                     <b style="color:rgb(68, 68, 68)">[Aug. 2022]</b>
                        <ul style="margin-bottom:5px">
                            <li> VITA Ph.D. student <a href="https://zhiwenfan.github.io/">Zhiwen Fan</a> is selected to receive a 2022 academic year Qualcomm Innovation Fellowship (QIF) </a> </li>
                            <li> VITA welcomes six new Ph.D. students: Zhenyu Zhang, Tong Wang, S P Sharan, Ruisi Cai, Wenyan Cong, and Jeffrey Lai </a> </li>
                            <li> 1 IEEE Trans. Medical Imaging (contrastive learning on X-rays) accepted</li> 
                            <li> 1 TMLR (all-pass lottery) accepted</li> 
                            <li> 1 ICDM'22 (stochastic KD for medical imaging) accepted</li> 
                            <li> 1 CIKM'22 (multi-modal recommendation) accepted</li> 
                            <li> Our group co-organized MLSys 2022 Tutorial: <a href="https://mlsys.org/virtual/2022/tutorial/2201">Training-Free Approaches for Edge AI: Challenges, Opportunities and Progress</a></li>
                        </ul>

                    <b style="color:rgb(68, 68, 68)">[Jul. 2022]</b>
                        <ul style="margin-bottom:5px">
                            <li> 8 ECCV'22 (SinNeRF + INR stylization + scalable L2O + point cloud MAE + few-shot align + malleable convolution + universal ViT + turbulence) accepted</li> 
                            <li> 1 TMLR (adversarial feature augmentation) accepted</li> 
                            <li>VITA Ph.D. student Xiaohan Chen graduated and joined Alibaba Damo Academy (Decision Intelligence Lab), Seattle, as a full-time senior research scientist ("Ali Star" hire)</li>
                            <li> Our group co-organized the 2nd workshop on <a href="https://www.sparseneural.net/home"> Sparsity in Neural Networks: Advancing Understanding and Practice (SNN) </a> </li>
                        </ul>

                    <b style="color:rgb(68, 68, 68)">[Jun. 2022]</b>
                        <ul style="margin-bottom:5px">
                            <li> Dr. Wang is grateful to receive the NSF CAREER Award </li>
                            <li> Dr. Wang is grateful to receive the Aharon Katzir Young Investigator Award of International Neural Network Society (INNS) </li>
                            <li> 1 ACM Computing Surveys (ML safety) accepted</li> 
                            <li> 1 TMLR (robust lifelong learning) accepted</li> 
                            <li> 3 ACM MM'22 (controllable light enhancement + video action detection + Cloud2Sketch) accepted</li> 
                            <li> 1 ACM BCB'22 (pretraining for  COVID-19 prediction) accepted</li> 
                            <li> 1 MLHC'22 (personalized imbalanced training) accepted</li> 
                            <li> Our group co-organized the CVPR 2022 Workshop and Challenge on <a href="http://cvpr2022.ug2challenge.org">Bridging Computational Photography and Visual Recognition (UG2+)</a></li>
                            <li> Our group co-organized the AICAS 2022 tutorial: <a href="https://aicas2022.org/?page_id=192"> IEEE Low-Power Computer Vision Challenge</a>. A similar tutorial would be offered in DAC 2022</li>
                        </ul>

                    <b style="color:rgb(68, 68, 68)">[May. 2022]</b>
                        <ul style="margin-bottom:5px">
                            <li> 9 ICML'22 (long-tail OoD detection + BN-free robust training + neural implicit dictionary + improved sparse training + linearity grafting + structured lottery ticket + double-win lottery ticket + renormalization group theory + NN architecture growing) accepted</li> 
                            <li> 1 AutoML-Conf'22 (GNN NAS) accepted</li> 
                        </ul>

                    <b style="color:rgb(68, 68, 68)">[Apr. 2022]</b>
                        <ul style="margin-bottom:5px">
                            <li> 1 JMLR (learning to optimize) accepted</li> 
                            <li>1 IEEE Trans. PAMI (deep GCN training benchmark) accepted</li>
                            <li> 1 ACM FAccT'22 (data efficiency under differential privacy) accepted</li> 
                            <li> We thank IEEE Computer Magazine <a href="https://www.computer.org/csdl/magazine/co/2022/04/09755195/1Cubx6Twc5G">[article]</a> for covering our recent success in building <a href="https://lpcv.ai/scoreboard/Video21">energy-efficient computer vision systems</a></li> 
                        </ul>

                    <b style="color:rgb(68, 68, 68)">[Mar. 2022]</b>
                        <ul style="margin-bottom:5px">
                            <li> We thank Quanta Magazine <a href="https://www.quantamagazine.org/will-transformers-take-over-artificial-intelligence-20220310/">[article]</a> for covering our NeurIPS'21 work, <a href="https://proceedings.neurips.cc/paper/2021/file/7c220a2091c26a7f5e9f1cfb099511e3-Paper.pdf">TransGAN</a></li>  
                            <li> We thank National Science Foundation (NSF) news <a href="https://www.nsf.gov/cise/news/NeuralArchitecture.pdf">[article]</a> for covering our training-free NAS works, in ICLR'21 (<a href="https://openreview.net/forum?id=Cnon5ezMHtu">TE-NAS</a>) and ICLR'22 (<a href="https://openreview.net/forum?id=H94a1_Pyr-6">As-ViT</a>)</li>
                        </ul>

                    <b style="color:rgb(68, 68, 68)">[Feb. 2022]</b>
                        <ul style="margin-bottom:5px">
                            <li> 7 CVPR'22 (ViT training + Aug-NeRF + symbolic spotting + sparsity for Trojan + sparse multi-tasking + video SR + fashion CLIP) accepted</li> 
                            <li> 1 IEEE Trans. Image Processing (light enhancement with noise) accepted</li> 
                        </ul>

                    <b style="color:rgb(68, 68, 68)">[Jan. 2022]</b>
                        <ul style="margin-bottom:5px">
                            <li> 14 ICLR'22 (symbolic L2O + disguised subnetwork + optimizer amalgamation + robust sparsity + Fourier ViT + auto-scaling ViT + ViT compression + Frank-Wolfe pruning + cold brew + audio lottery + split-max federated learning + sparse ensembling + random sparse training + Bayesian L2O) accepted </a> </li>
                            <li> 1 AISTATS'22 (variational feature selection) accepted </a> </li>
                            <li> 2 ICASSP'22 (lifelong speech synthesis + sensor data imputation) accepted </a> </li>
                            <li> 1 ACM Trans. DAES (efficient segmentation) accepted </a> </li>
                            <li> VITA Ph.D. student <a href="https://tianlong-chen.github.io/about/">Tianlong Chen</a> is selected to receive a 2022 academic year Adobe PhD Research Fellowship - that is after him being awarded IBM PhD Fellowship 2021, UT Graduate Dean’s Prestigious Fellowship 2021, and Baidu Scholarship finalist </a> </li>
                            <li> VITA welcomes four new Ph.D. students: Xuxi Chen, Dejia Xu, Hongru Yang and Zhangheng Li </a> </li>
                        </ul>

                    <b style="color:rgb(68, 68, 68)">[Dec. 2021]</b>
                        <ul style="margin-bottom:5px">
                            <li> People in this group did nothing this month but enjoyed some well-deserved vacation time, with their families and loved ones </a> </li>
                        </ul>

                    <b style="color:rgb(68, 68, 68)">[Nov. 2021]</b>
                        <ul style="margin-bottom:5px">
                            <li> 1 IEEE Trans. Neural Networks and Learning Systems (algorithm-hardware co-design to reduce data movement) accepted </li>
                            <li> 1 AAAI'22 (federated sparse training) accepted </li>
                            <li> Our group co-organized the 2nd IEEE Workshop on <a href="https://sites.google.com/view/slowdnn2021/"> Seeking Low-dimensionality in Deep Neural Networks (SLowDNN)</a> </li>
                        </ul>


                    <b style="color:rgb(68, 68, 68)">[Oct. 2021]</b>
                        <ul style="margin-bottom:5px">
                            <li> 1 WSDM'22 (graph contrastive learning) accepted </li>
                            <li> 1 IEEE Trans. SPIN (vision-based drone swarm control) accepted </li>
                            <li> 3 WACV'22 (video NAS + sandwich BatchNorm +  chest X-rays) accepted </li>
                            <li> Our group is selected to be supported by the Google TensorFlow Model Garden Award </li>
                            <li> Our group co-organized the ICCV 2021 Workshop on <a href="https://rlq-workshop.github.io/">  Real-world Recognition from Low-quality Inputs (RLQ) </a> </li> 
                            <li> VITA Postdoctoral Researcher Dr. Guoliang Kang joins the CS department of University of Technology Sydney, Australia, as Lecturer (Assistant Professor) and endowed with the prestigious DECRA Fellow </a> </li> 
                            <li> We thank Henry for making a very cool video <a href="https://www.youtube.com/watch?v=kQ09eg513Nc">[Youtube]</a> highlighting our latest work, AugMax (NeurIPS'21) <a href="https://arxiv.org/pdf/2110.13771.pdf">[Paper]</a> <a href="https://github.com/VITA-Group/AugMax">[Code]</a></li> 
                        </ul>


                    <b style="color:rgb(68, 68, 68)">[Sep. 2021]</b>
                        <ul style="margin-bottom:5px">
                            <li>13 NeurIPS'21 (TransGAN + AugMax + data-efficient GAN + elastic lottery ticket + SViTE + DePT + stealing lottery + imbalanced contrastive learning + HyperLISTA + WeakNAS + IA-RED<sup>2</sup> + neuroregeneration + lottery ticket benchmark) accepted </li>
                            <li>Our group won the 1st prize of <a href="https://lpcv.ai/scoreboard/Video21">IEEE 2021 Low-Power Computer Vision Challenge</a> (video track) <a href="https://github.com/VITA-Group/21LPCV-UAV-Solution"> [Solution] </a> <a href="https://arxiv.org/pdf/2204.04416.pdf"> [Tech Report] </a></li>
                            <li>1 ICCV'21 workshop (graph CNN for motion prediction) accepted</li>
                        </ul>



                     <b style="color:rgb(68, 68, 68)">[Aug. 2021]</b>
                        <ul style="margin-bottom:5px">
                            <li> VITA welcomes six new Ph.D. students: Zhiwen Fan, Scott Hoang, Peihao Wang, Greg Holste, Ajay Jaiswal and Everardo Olivares-Vargas </a> </li>
                             <li> VITA's August 2021 squad of students graduated: Dr. Zhenyu Wu joined Wormpex AI Research (Seattle) as Research Scientist, Scott continues as VITA Ph.D. student, and Rahul joined ByteDance AI Lab (Silicon Valley) as Machine Learning Engineer. Congratulations! </li>
                             <li>1 IEEE Trans. Image Processing (sketch-to-image synthesis) accepted</li> 
                             <li>1 Springer Machine Learning (weakly-supervised segmentation troubleshooting) accepted</li> 
                        </ul>


                          <b style="color:rgb(68, 68, 68)">[Jul. 2021]</b>
                        <ul style="margin-bottom:5px">
                            <li> 3 ICCV'21 (image harmonization + video NAS + pruning) accepted </li>
                            <li> Our group co-organized the inaugural workshop on <a href="https://www.sparseneural.net/ "> Sparsity in Neural Networks: Advancing Understanding and Practice (SNN) </a> </li>
                             <li> VITA Ph.D. student <a href="https://tianlong-chen.github.io/about/">Tianlong Chen</a> is selected to receive UT Graduate Dean’s Prestigious Fellowship, and <a href="http://www.xiaohanchen.com/">Xiaohan Chen</a>  is selected as a Qualcomm Innovation Fellowship 2021 finalist </li>
                        </ul>


                        <b style="color:rgb(68, 68, 68)">[Jun. 2021]</b>
                        <ul style="margin-bottom:5px">
                            <li> Dr. Wang is grateful to receive the 2021 J. P. Morgan Faculty Research Award </li>
                            <li>1 ACM ToMM (detecting GAN mode collapse) accepted</li>
                            <li>2 IEEE BHI'21 (meta learning for EHR data + MoE for EHR data) accepted</li>
                            <li> Our group co-organized the CVPR 2021 tutorial: <a href="https://vita-group.github.io/cvpr_2021_data_efficient_tutorial.html"> Data- and Label-Efficient Learning in An Imperfect World</a></li>   
                            <li>Our group co-organized two CVPR 2021 workshops:  <a href="http://cvpr2021.ug2challenge.org">Bridging Computational Photography and Visual Recognition (UG2+)</a>, and <a href="http://fvc-workshop.github.io">Future Video Conferencing (FVC) </a></li>
                            <li> We thank Henry for making a very cool video <a href="https://www.youtube.com/watch?v=G3wjQEn0pQ0">[Youtube]</a> highlighting our latest work, self-damaging contrastive learning (ICML'21) <a href="https://arxiv.org/abs/2106.02990">[Paper]</a> <a href="https://github.com/VITA-Group/SDCLR">[Code]</a></li> 
                        </ul>


                          <b style="color:rgb(68, 68, 68)">[May. 2021]</b>
                        <ul style="margin-bottom:5px">
                            <li> 5 ICML'21 (graph contrastive learning + homotopy attack + imbalanced contrastive learning +  graph lottery ticket + data-efficient lottery ticket) accepted </li>
                            <li> 1 KDD'21 (federated learning debiasing) accepted </li>
                            <li> 1 ACL'21 (EarlyBERT) accepted </li>
                            <li> Our group is selected to be supported by the <a href="https://www.nvidia.com/en-us/industries/higher-education-research/applied-research-program/">NVIDIA Applied Research Accelerator Program</a> </li>
                        </ul>

                        <b style="color:rgb(68, 68, 68)">[Apr. 2021]</b>
                        <ul style="margin-bottom:5px">   
                            <li> VITA Ph.D. student <a href="https://tianlong-chen.github.io/about/">Tianlong Chen</a> is selected to receive a <a href="https://www.research.ibm.com/university/awards/fellowships-awardees.html">2021 academic year IBM PhD Fellowship</a> -- that is after Tianlong being selected as a Baidu Scholarship 2021 finalist </li>
                            <li>2 CVPR'21 workshop (CNN high-frequency bias + BN-free training of binary networks) accepted</li>
                        </ul>

                        <b style="color:rgb(68, 68, 68)">[Mar. 2021]</b>
                        <ul style="margin-bottom:5px">
                            <li> 1 ICME'21 (arbitrary style transfer) accepted </li>
                             <li> We thank UT Engineering News <a href="https://www.engr.utexas.edu/news/archive/9204-5-questions-with-cockrells-newest-machine-learning-and-artificial-intelligence-expert-atlas-wang">[article]</a> for highlighting our group's research </a></li>      
                        </ul>

                         <b style="color:rgb(68, 68, 68)">[Feb. 2021]</b>
                        <ul style="margin-bottom:5px">
                            <li> 3 CVPR'21 (CV lottery ticket + blind image IQA + assessing image enhancement) accepted </li>
                            <li>1 IJCV (open-world generalization of segmentation models) accepted</li>
                             <li> 1 DAC'21 + 1 ICASSP'21 accepted (InstantNet + VGAI)</a></li>  
                             <li> We thank Yannic for making a very cool video <a href="https://www.youtube.com/watch?v=R5DiLFOMZrc&feature=youtu.be">[Youtube]</a> highlighting our latest work, TransGAN <a href="https://arxiv.org/abs/2102.07074">[Paper]</a> <a href="https://github.com/VITA-Group/TransGAN">[Code]</a></li>              
                        </ul>
                          <b style="color:rgb(68, 68, 68)">[Jan. 2021]</b>
                        <ul style="margin-bottom:5px">
                             <li>8 ICLR'21 (lifelong lottery ticket + robust overfitting + nasty knowledge distillation + theory-guided NAS + domain generalization + LISTA unrolling + learning to optimize for minimax + efficient recommendation system) accepted</li>
                             <li>1 IEEE Trans. PAMI (artistic text style transfer) accepted</li>
                            <li> We thank IDG Connect <a href="https://www.idgconnect.com/article/3602888/reducing-energy-use-in-neural-networks.html">[article]</a> for covering our ICLR'20 work, <a href="https://openreview.net/forum?id=BJxsrgStvr">Early Bird Lottery Ticket for Effcient Deep Learning </a></li>   
                            <li>Our group co-organized the <a href="https://sites.google.com/view/ijcai-boom2020/home?authuser=1/">IJCAI 2020 BOOM Workshop</a></li>
                            <li> VITA welcomes new Ph.D. student Wenqing Zheng (Spring 2021 - )</a></li>                    
                        </ul>
                             <b style="color:rgb(68, 68, 68)">[Dec. 2020]</b>
                        <ul style="margin-bottom:5px">
                            <li>1 AAAI'21 (L2O for privacy protection) accepted</li>
                            <li>1 IEEE Trans. Image Processing (EnlightenGAN) accepted</li>
                            <li>1 Journal of Chemical Information and Modeling (explainable deep learning for bioinformatics) accepted</li>
                            <li> We thank MIT News <a href="https://news.mit.edu/2020/neural-model-language-1201">[article]</a> for covering our NeurIPS'20 work, <a href="https://proceedings.neurips.cc/paper/2020/file/b6af2c9703f203a2794be03d443af2e3-Paper.pdf">BERT Lottery Ticket Hypothesis </a></li>                           
                             <li> We thank US Army Research Lab for selecting our work of <a href="https://arxiv.org/abs/2002.02308">vision-based decentralized robotic control </a> as No. 3 in US ARL’s  <a href="https://www.army.mil/article/242136">“10 Coolest Techniques”</a> of Year 2020 [<a href="https://www.youtube.com/watch?v=6sg-4CxNbBk&feature=youtu.be&ab_channel=U.S.ArmyCCDCArmyResearchLaboratory">Video Demo</a>]
                             <li>Our group co-organized the <a href="https://www.hadr.ai">NeurIPS 2020 Workshop on AI for Humanitarian Assistance and Disaster Response (HADR)</a></li>
                             <li>VITA's December 2020 squad of M.S. students graduated: Ting-Kuei joined Qualcomm Research as Senior Deep Learning Engineer, Yunhe joined ByteDance AI Lab as Research Engineer, and Sicheng joined Walmart as Data Scientist. Congratulations!</a></li>
                        </ul>
                             <b style="color:rgb(68, 68, 68)">[Nov. 2020]</b>
                        <ul style="margin-bottom:5px">
                            <li>1 IJCV (single image deraining benchmark) accepted</li>
                            <li>Our group co-organized the 1st IEEE Workshop on <a href="https://sites.google.com/view/slowdnn/">Seeking Low-dimensionality in Deep Neural Networks (SLowDNN)</a> <a href="https://www.youtube.com/playlist?from=timeline&list=PL7P834wcUN3eSh7Nn4wzPBjEnme4Rls7n&app=desktop">[video record]</a></li>
                            
                        </ul>
                        <b style="color:rgb(68, 68, 68)">[Oct. 2020]</b>
                        <ul style="margin-bottom:5px">
                            <li>Our three popular image enhancement algorithms: AOD-Net (ICCV 2017), EnlightenGAN (IEEE TIP 2020), and DeblurGAN-V2 (ICCV 2019), are included into the open-source GNU Image Manipulation Program toolbox <a href="https://github.com/kritiksoman/GIMP-ML?fbclid=IwAR2ZcF0oKKItGQQFuxfvFxAfDOCW8FoEDISzkoFOmT130Vo7bQCcONJqbgg">(GIMP-ML)</a>, as <a href="https://www.youtube.com/watch?v=VWl6tyylO50&list=PLo9r5wFmpD5dRfeIthwuL52eNdXthRE7V&index=6&ab_channel=KritikSoman">deep-dehazing</a>, <a href="https://www.youtube.com/watch?v=SHrEWMWZ0dE&list=PLo9r5wFmpD5dRfeIthwuL52eNdXthRE7V&index=3&ab_channel=KritikSoman">enlighten</a>, and <a href="https://www.youtube.com/watch?v=adgHtu4chyU&list=PLo9r5wFmpD5dLWTyo6NOiD6BJjhfEOM5t&index=3&ab_channel=KritikSoman">deblur</a> plugins</li>
                        </ul>
                        <b style="color:rgb(68, 68, 68)">[Sep. 2020]</b>
                        <ul style="margin-bottom:5px">
                            <li> Dr. Wang is grateful to receive the 2020 Adobe Data Science Research Award </li>
                            <li>8 NeurIPS'20 (learning to optimize + once-for-all adversarial training + BERT lottery ticket + meta learning + robust contrastive learning + graph contrastive learning + ShiftAddNet + efficient quantized training) accepted</li>
                            <li>1 IEEE Trans. PAMI (privacy-preserving visual recognition) accepted</li>
                        </ul>
                        <b style="color:rgb(68, 68, 68)">[Aug. 2020]</b>
                        <ul style="margin-bottom:5px">
                            <li>VITA's first Ph.D. student Ye Yuan graduated and joined ByteDance AI Lab, Silicon Valley, as a full-time researcher. A Memorable Point for both Ye and the group - Congratulations Ye!</li>
                            <li>Our group won the 2nd place of <a href="https://lpcv.ai/scoreboard/Video20">IEEE 2020 Low-Power Computer Vision Challenge</a> (video track)</li>
                            <li>Our group co-organized the <a href="https://rlq-tod.github.io">ECCV 2020 RLQ-TOD Workshop and Prize Challenge</a> <a href="https://www.youtube.com/playlist?list=PLPtQK8rJZ9HzU0ao9-Zdy-vmCc_Rw-9U8">[video record]</a></li>
                            <li>1 IEEE Trans. GRS (deep hyperspectral image classification) accepted</li>
                        </ul>
                        <b style="color:rgb(68, 68, 68)">[Jul. 2020]</b>
                        <ul style="margin-bottom:5px">
                            <li>3 ECCV'20 (GAN compression + sketch-to-image synthesis + on-device learning-to-optimize) accepted</li>
                            <li>1 ACM Multimedia'20 (MMHand synthesizer) accepted </li>
                               <li>1 InterSpeech'20 (AutoSpeech) accepted</li>
                            <li> We thank Tech Xplore <a href="https://techxplore.com/news/2020-07-deep-neural-networks-adversarial-d.html">[article]</a> for covering our work, <a href="https://arxiv.org/abs/2006.14655">adversarial 3-D logos </a></li>  
                        </ul>
                        <b style="color:rgb(68, 68, 68)">[Jun. 2020]</b>
                        <ul style="margin-bottom:5px">
                            <li>6 ICML'20 (domain generalization + noisy label training + self-supervised GCN + DNN optimization + GAN compression + NAS for Bayesian models) accepted</li>
                            <li>Our group co-organized the <a href="www.ug2challenge.org">CVPR 2020 UG2+ Workshop and Prize Challenge</a></li>
                        </ul>
                        <b style="color:rgb(68, 68, 68)">[May. 2020]</b>
                        <ul style="margin-bottom:5px">
                            <li>1 IEEE Trans. PAMI (image enhancement for visual understanding) accepted</li>
                            <li> 1 IEEE Trans.  Mobile Computing (adaptive model compression) accepted</li>
                        </ul>
                        <b style="color:rgb(68, 68, 68)">[Apr. 2020]</b>
                        <ul style="margin-bottom:5px">
                            <li> Dr. Wang is grateful to receive the 2020 ARO Young Investigator Award (YIP) </li>
                            <li> Dr. Wang is grateful to receive the 2020 IBM Faculty Research Award </li>
                            <li> Dr. Wang is grateful to receive the 2020 Amazon Research Award (AWS AI) </li>
                            <li>2 CVPR'20 workshop (efficient triplet loss + fine-grained classification) accepted</li>
                        </ul>
                        <b style="color:rgb(68, 68, 68)">[Mar. 2020]</b>
                        <ul style="margin-bottom:5px">
                            <li>1 ISCA'20 (algorithm-hardware co-design to reduce data movement) accepted</li>
                        </ul>
                        <b style="color:rgb(68, 68, 68)">[Feb. 2020]</b>
                        <ul style="margin-bottom:5px">
                            <li>3 CVPR'20 (self-supervised adversarial robustness + fast GCN training + indoor scene reasoning) accepted</li>
                            <li>1 IEEE Trans. Image Processing (visual understanding in poor-visibility environments) accepted</li>                           
                        </ul>
                        <b style="color:rgb(68, 68, 68)">[Jan. 2020]</b>
                        <ul>
                            <li>
                                 1 AISTATS'20 (CNN uncertainty quantification) accepted</li>
                                <li> 1 IEEE Trans. CSVT (GAN data augmentation) accepted 
                            </li>
                        </ul>
                    </div>
                </div>
            </div>
            <div class="col-lg-12">
                <div class="section-title">
                    <h2>Research Interests</h2>
                </div>
                <div class="trend-entry d-flex">
                    <div class="trend-contents">
                        <h4>[A] As Goals -- Enhancing Deep Learning Robustness, Efficiency, and Privacy</h4>
                        <p>
                           We seek to build deep learning solutions that are way beyond just data-driven accurate predictors. In our opinion, an ideal model shall at least: (1) be robust to various perturbations, distribution shifts, and adversarial attacks; (2) be efficient for both inference and training, including resource-efficient, data-efficient, and label-efficient; and (3) be designed to respect individual privacy and fairness.
                        </p>
                        <h4>[B] As Toolkits -- AutoML, and and Emerging New Models </h4>
                        <p>
                           We are enthusiastic about AutoML, on both consolidating its theoretical underpinnings and broadening its practical applicability. State-of-the-art ML systems consist of complex pipelines, with various design choices. We consider AutoML to be a powerful tool and a central hub, in addressing those design challenges faster and better. Our recent work focuses on the data-driven discovery of model architectures (i.e., neural architecture search) and training algorithms (a.k.a. “learning to optimize”). We are meanwhile devoted to studying uprising ML models that show to be potentially “universal” workhorses, such as transformers and graph neural networks.
                        </p>
                        <h4>[C] As Applications -- Computer Vision and Interdisciplinary Problems</h4>
                        <p>
                            We are interested in a broad range of computer vision problems, ranging from low-level (e.g, image reconstruction, enhancement, and generation) to high-level topics (e.g., recognition, segmentation, and vision for UAV/autonomous driving). We are also growingly interested in several interdisciplinary fields, such as biomedical informatics, geoscience, IoT and cyber-physical systems. 
                        </p>
                        <!-- <br> -->
                        <h5><a href="./prospective_students.html">Prospective students</a></h5>
                    </div>
                </div>
            </div>

            

        <div class="col-lg-12" id="sponsor">
            <div class="section-title" style="padding-top: 50px">
                <h2>Sponsor</h2>
            </div>
            <div class="trend-entry d-flex">
                <div class="row justify-content-md-center">
                    <div>
                        <img src="./123.png" width="100%"/>
                    </div>
                </div>
            </div>
        </div>

        </div>
    </div>
</div>
        
<!-- END section -->


<div class="footer">
    <div class="container">
        <div class="row">
            <div class="col-12">
                <div class="copyright">
                    <p>
                        <!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
                        Copyright &copy;<script>document.write(new Date().getFullYear());</script>
                        All rights reserved | Built upon <a
                            href="https://colorlib.com" target="_blank">Colorlib</a>
                        <!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
                        </p>
                        
                </div>
            </div>
        </div>
    </div>
</div>

</div>
<!-- .site-wrap -->


<!-- loader -->
<!-- <div id="loader" class="show fullscreen">
    <svg class="circular" width="48px" height="48px">
        <circle class="path-bg" cx="24" cy="24" r="22" fill="none" stroke-width="4" stroke="#eeeeee"/>
        <circle class="path" cx="24" cy="24" r="22" fill="none" stroke-width="4" stroke-miterlimit="10"
                stroke="#ff5e15"/>
    </svg>
</div> -->

<script src="js/jquery-3.3.1.min.js"></script>
<script src="js/jquery-migrate-3.0.1.min.js"></script>
<script src="js/jquery-ui.js"></script>
<script src="js/popper.min.js"></script>
<script src="js/bootstrap.min.js"></script>
<script src="js/owl.carousel.min.js"></script>
<script src="js/jquery.stellar.min.js"></script>
<script src="js/jquery.countdown.min.js"></script>
<script src="js/bootstrap-datepicker.min.js"></script>
<script src="js/jquery.easing.1.3.js"></script>
<script src="js/aos.js"></script>
<script src="js/jquery.fancybox.min.js"></script>
<script src="js/jquery.sticky.js"></script>
<script src="js/jquery.mb.YTPlayer.min.js"></script>

<script src="js/main.js"></script>

</body>

</html>
